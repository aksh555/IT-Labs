{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from math import sqrt\n",
    "from statsmodels.formula.api import ols\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df = pd.read_csv('../Lab 1/spotify.csv')\n",
    "df_t = pd.read_csv('../Lab 1/StateTestingDetails.csv')\n",
    "df_p = pd.read_csv('../Lab 1/population_india_census2011.csv')\n",
    "df_n = pd.read_csv('../Lab 1/netflix_titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. z-tests on Spotify dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of mean acousticness value for the population (2018-2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population parameters\n",
      "Size = 4052, Mean = 0.27276311065399717, Std = 0.2831018020164635\n"
     ]
    }
   ],
   "source": [
    "print(f'Population parameters')\n",
    "df1 = df[df['year']!=2020]\n",
    "df1 = df1[df1['year']>= 2018]\n",
    "pop_num = df1.shape[0]\n",
    "pop_mean  = df1['acousticness'].mean()\n",
    "pop_std = df1['acousticness'].std()\n",
    "\n",
    "print(f\"Size = {pop_num}, Mean = {pop_mean}, Std = {pop_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of mean acousticness value and standard deviation of random sample (300 songs) from Yr 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample statistics: Yr 2020\n",
      "Size = 300, Mean = 0.224682919, Std: 0.24729447700072327\n"
     ]
    }
   ],
   "source": [
    "print(f'Sample statistics: Yr 2020')\n",
    "samp_num = 300\n",
    "\n",
    "df1 = df[df['year']==2020]\n",
    "df1 = df1.sample(random_state=42, n=samp_num)\n",
    "samp_mean = df1['acousticness'].mean()\n",
    "samp_std = df1['acousticness'].std()\n",
    "\n",
    "print(f'Size = {samp_num}, Mean = {samp_mean}, Std: {samp_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one-tailed test is when the critical area of a distribution is one-sided (either greater than or less than a certain value, but not both). If the sample being tested falls into the one-sided critical area, the alternative hypothesis will be accepted.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left tailed z test\n",
      "Null Hypothesis H0 : μx = μy\n",
      "Alternate Hypotheis H1 : μx < μy\n",
      "Alpha value is : 0.05\n",
      "Critical value (actual_z): -1.6448536269514729\n",
      "Test statistic (hypo_z): -2.9416038396509134 \n",
      "\n",
      "Reject Null Hypothesis\n"
     ]
    }
   ],
   "source": [
    "print('Left tailed z test')\n",
    "alpha  = 0.05\n",
    "\n",
    "print(\"Null Hypothesis H0 : μx = μy\")\n",
    "print('Alternate Hypotheis H1 : μx < μy')\n",
    "print(\"Alpha value is :\", alpha)\n",
    "\n",
    "actual_z = abs(stats.norm.ppf(alpha))\n",
    "hypo_z = (samp_mean - pop_mean)/(pop_std/sqrt(samp_num))\n",
    "\n",
    "print('Critical value (actual_z):',-actual_z)\n",
    "print('Test statistic (hypo_z):',hypo_z,'\\n')\n",
    "\n",
    "if hypo_z < -(actual_z):\n",
    "    print(\"Reject Null Hypothesis\")\n",
    "else:\n",
    "    print(\"Failed to reject Null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null hypothesis**: Acoustic values in songs of 2020 is similar to the population (2018-2020) values \n",
    "  \n",
    "  H0: μx = μy\n",
    "  \n",
    "**Alternative hypothesis**: Acoustic values in songs of 2020 is lesser than the population\n",
    "  \n",
    "  H1: μx < μy\n",
    "\n",
    "As we do have the variance of the population, we employ a left tailed z-test to suggest whether there is a significant reduction in the acoustic effect of songs in the year 2020. As the test statistic is less than critical value (it lies in the 5% of the leftmost region).\n",
    "\n",
    "**Hence H0 is rejected**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of mean song title length for the population (2018-2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population parameters\n",
      "Size = 4052, Mean = 3.0772458045409676, Std = 2.137856988061137\n"
     ]
    }
   ],
   "source": [
    "df['name_len'] = df['name'].str.split().str.len()\n",
    "df1 = df[df['year']!=2020]\n",
    "df1 = df1[df1['year']>= 2018]\n",
    "\n",
    "print(f'Population parameters')\n",
    "pop_num = df1.shape[0]\n",
    "pop_mean  = df1['name_len'].mean()\n",
    "pop_std = df1['name_len'].std()\n",
    "\n",
    "print(f\"Size = {pop_num}, Mean = {pop_mean}, Std = {pop_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of mean song title length of random sample (300 songs) from Yr 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample statistics: Yr 2000\n",
      "Size = 300, Mean = 3.3366666666666664, Std: 2.3110876174376878\n"
     ]
    }
   ],
   "source": [
    "print(f'Sample statistics: Yr 2000')\n",
    "samp_num = 300\n",
    "\n",
    "df1 = df[df['year']==2020]\n",
    "df1 = df1.sample(random_state=42, n=samp_num)\n",
    "samp_mean = df1['name_len'].mean()\n",
    "samp_std = df1['name_len'].std()\n",
    "\n",
    "print(f'Size = {samp_num}, Mean = {samp_mean}, Std: {samp_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A two-tailed test is when critical area of a distribution is two-sided and tests whether a sample is greater or less than a range of values. If the sample being tested falls into either of the critical areas, the alternative hypothesis is accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tailed z test\n",
      "Null Hypothesis H0 : μx = μy\n",
      "Alternate Hypotheis H1 : μx < μy\n",
      "Alpha value is : 0.01\n",
      "Critical value (actual_z): 2.575829303548901\n",
      "Test statistic (hypo_z): 2.1017781650237373 \n",
      "\n",
      "Failed to reject Null hypothesis\n"
     ]
    }
   ],
   "source": [
    "print('2 tailed z test')\n",
    "# critical significance level\n",
    "alpha  = 0.01\n",
    "\n",
    "print(\"Null Hypothesis H0 : μx = μy\")\n",
    "print('Alternate Hypotheis H1 : μx < μy')\n",
    "print(\"Alpha value is :\", alpha)\n",
    "\n",
    "actual_z = abs(stats.norm.ppf(alpha/2))\n",
    "hypo_z = (samp_mean - pop_mean)/(pop_std/sqrt(samp_num))\n",
    "\n",
    "print('Critical value (actual_z):',actual_z)\n",
    "print('Test statistic (hypo_z):',hypo_z, '\\n')\n",
    "\n",
    "if hypo_z >= actual_z or hypo_z <=-(actual_z):\n",
    "    print(\"Reject Null Hypothesis\")\n",
    "else:\n",
    "    print(\"Failed to reject Null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null hypothesis**: Legth of title of songs of 2020 is similar to the population 2018-2020 values \n",
    "  \n",
    "  H0: μx = μy\n",
    "  \n",
    "**Alternative hypothesis**:  Legth of title of songs of 2020 is different from the population\n",
    "  \n",
    "  H1: μx != μy\n",
    "\n",
    "As we have the variance of the population, we employ a 2 tailed z-test with 0.01 significance level to suggest whether there is a significant difference in the title length of songs in the year 2020. Here we choose alpha = 0.01 critical significance value as the outcome of the results of this test would help artists to decide song names in future as 2020 songs were very popular. It directly affects the artists' earning and audience appeal. As the test statistic is less than negative critical value (it lies in the 2.5% of the leftmost region).\n",
    "\n",
    "**Hence H0 NOT rejected**\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. t-tests on Spotify dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of mean popularity and standard deviation of songs before 2000 from a sample size of 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 statistics: Before Yr 2000\n",
      "Size = 50, Mean = 25.26, Std: 18.08010520106652\n"
     ]
    }
   ],
   "source": [
    "print(f'Sample 1 statistics: Before Yr 2000')\n",
    "samp1_num = 50\n",
    "ddof1 = samp1_num - 1\n",
    "\n",
    "df1 = df[df['year']<2000]\n",
    "df1 = df1.sample(random_state=42, n=samp1_num)\n",
    "samp1_mean = df1['popularity'].mean()\n",
    "samp1_std = df1['popularity'].std()\n",
    "\n",
    "print(f'Size = {samp1_num}, Mean = {samp1_mean}, Std: {samp1_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of mean popularity and standard deviation of songs after 2000 from a sample size of 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2 statistics: After Yr 2000\n",
      "Size = 50, Mean = 52.42, Std: 15.01983722295557\n"
     ]
    }
   ],
   "source": [
    "print(f'Sample 2 statistics: After Yr 2000')\n",
    "samp2_num = 50\n",
    "ddof2 = samp2_num - 1\n",
    "\n",
    "df1 = df[df['year']>=2000]\n",
    "df1 = df1.sample(random_state=42, n=samp2_num)\n",
    "samp2_mean = df1['popularity'].mean()\n",
    "samp2_std = df1['popularity'].std()\n",
    "\n",
    "print(f'Size = {samp2_num}, Mean = {samp2_mean}, Std: {samp2_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 independent sample Right-tailed t test\n",
      "Null Hypothesis H0 : μx = μy\n",
      "Alternate Hypotheis H1 : μx != μy\n",
      "Alpha value is : 0.05\n",
      "16.62055525976365\n",
      "Critical value (actual_z): 1.6605512170440575\n",
      "Test statistic (hypo_z): -8.170605486854903 \n",
      "\n",
      "Failed to reject Null hypothesis\n"
     ]
    }
   ],
   "source": [
    "print('2 independent sample Right-tailed t test')\n",
    "alpha  = 0.05\n",
    "ddof = ddof1 + ddof2\n",
    "\n",
    "print(\"Null Hypothesis H0 : μx = μy\")\n",
    "print('Alternate Hypotheis H1 : μx != μy')\n",
    "print(\"Alpha value is :\", alpha)\n",
    "\n",
    "# pooled std dev (same population)\n",
    "std_pool = sqrt((ddof1*(samp1_std ** 2) + ddof2*(samp2_std ** 2))/ddof)\n",
    "print(f'Pooled variance: {std_pool}')\n",
    "actual_z = abs(stats.t.ppf(alpha, ddof))\n",
    "hypo_z = (samp1_mean - samp2_mean)/(std_pool*sqrt((1/samp1_num + 1/samp2_num)))\n",
    "\n",
    "print('Critical value (actual_z):',actual_z)\n",
    "print('Test statistic (hypo_z):',hypo_z, '\\n')\n",
    "\n",
    "if hypo_z >= actual_z:\n",
    "    print(\"Reject Null Hypothesis\")\n",
    "else:\n",
    "    print(\"Failed to reject Null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null hypothesis**: There is no significant difference in the mean popularity of songs before and after year 2000\n",
    "  \n",
    "  H0: μx = μy\n",
    "  \n",
    "**Alternative hypothesis**: There is an increase in the mean popularity of songs after year 2000\n",
    "  \n",
    "  H1: μx > μy\n",
    "\n",
    "As the 2 sample are independent and we don't know the variances, we employ a right tailed t-test to suggest whether there is a significant increase in the mean popularity of songs after year 2000 compared to before. Here the population is same, so pooled variance is used and DoF = n1 + n2 - 2. As the test statistic is less than critical value (it lies in the 95% region).\n",
    "\n",
    "**Hence H0 NOT rejected**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. chi-squared test on Netflix dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if there is any dependence between type of show and target audience (children/adults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = df_n[df_n['rating'].notna()]\n",
    "df_n = df_n.reset_index(drop=True)\n",
    "df_n['aud_cat'] = None\n",
    "\n",
    "for index, row in df_n.iterrows():\n",
    "    if row['rating'] in ['TV-14', 'TV-PG', 'R', 'PG-13']:\n",
    "        df_n['aud_cat'].iloc[index] = 'child'\n",
    "    else:\n",
    "        df_n['aud_cat'].iloc[index] = 'adult'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>aud_cat</th>\n",
       "      <th>adult</th>\n",
       "      <th>child</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Movie</th>\n",
       "      <td>2546</td>\n",
       "      <td>2826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TV Show</th>\n",
       "      <td>1446</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "aud_cat  adult  child\n",
       "type                 \n",
       "Movie     2546   2826\n",
       "TV Show   1446    962"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contigency_tab = pd.crosstab(df_n['type'], df_n['aud_cat']) \n",
    "contigency_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic = 106.09479267108279\n",
      "P-value = 7.02910957152232e-25\n",
      "DoF = 1\n",
      "Reject Null Hypothesis\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "chi_stat, p, dof, expected = stats.chi2_contingency(contigency_tab)\n",
    "print(f'Test statistic = {chi_stat}\\nP-value = {p}\\nDoF = {dof}')\n",
    "if p < alpha:\n",
    "    print(\"Reject Null Hypothesis\")\n",
    "else:\n",
    "    print(\"Failed to reject Null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null hypothesis**: There is no dependency between type of show (TV/movie) and target audience (children/adults).\n",
    "  \n",
    "  H0: μx = μy\n",
    "  \n",
    "**Alternative hypothesis**: There is dependence between show type and audience targetted\n",
    "  \n",
    "  H1: μx != μy\n",
    "\n",
    "Since the 2 are categorical variables we employ the Chi-squared test for association/independence. As obtained p value is very low (< alpha)\n",
    "\n",
    "**Hence H0 rejected**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ANOVA on covid dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 way anova test to study if density of a region affects the count of covid positive cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t['Positive'] = df_t['Positive'] + 1\n",
    "stateMedian = df_t.groupby('State')[['Positive']].median().reset_index().rename(columns={'Positive':'Median'})\n",
    "for index,row in df_t.iterrows():\n",
    "    if pd.isnull(row['Positive']):\n",
    "        df_t['Positive'][index] = int(stateMedian['Median'][stateMedian['State'] == row['State']])\n",
    "df_t['Positive'].sort_values()\n",
    "data=pd.merge(df_t, df_p, on='State')\n",
    "data['Positive'].sort_values()\n",
    "\n",
    "# Create density groups\n",
    "def density(data):\n",
    "    data['density_grp']=0\n",
    "    for index,row in data.iterrows():\n",
    "        status=None\n",
    "        i=row['Density'].split('/')[0]\n",
    "        try:\n",
    "            if (',' in i):\n",
    "                i=int(i.split(',')[0]+i.split(',')[1])\n",
    "            elif ('.' in i):\n",
    "                i=round(float(i))\n",
    "            else:\n",
    "                i=int(i)\n",
    "        except ValueError as err:\n",
    "            pass\n",
    "        try:\n",
    "            if (0<i<=300):\n",
    "                status = 'Dense1'\n",
    "            elif (300<i<=600):\n",
    "                status = 'Dense2'\n",
    "            elif (600<i<=900):\n",
    "                status = 'Dense3'\n",
    "            else:\n",
    "                status = 'Dense4'\n",
    "        except ValueError as err:\n",
    "            pass\n",
    "        data['density_grp'].iloc[index]=status\n",
    "    return data\n",
    "\n",
    "data['Positive'].sort_values()\n",
    "# Map each state as per its density group\n",
    "data=density(data)\n",
    "stateDensity=data[['State','density_grp']].drop_duplicates().sort_values(by='State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Dense1':random.sample(list(data['Positive'][data['density_grp']=='Dense1']), 10),\n",
    "                      'Dense2':random.sample(list(data['Positive'][data['density_grp']=='Dense1']), 10),\n",
    "                      'Dense3':random.sample(list(data['Positive'][data['density_grp']=='Dense1']), 10),\n",
    "                      'Dense4':random.sample(list(data['Positive'][data['density_grp']=='Dense1']), 10)})\n",
    "\n",
    "# BoxCox Transformation to bring the data to close to Gaussian Distribution\n",
    "df['Dense1'],fitted_lambda = stats.boxcox(df['Dense1'])\n",
    "df['Dense2'],fitted_lambda = stats.boxcox(df['Dense2'])\n",
    "df['Dense3'],fitted_lambda = stats.boxcox(df['Dense3'])\n",
    "df['Dense4'],fitted_lambda = stats.boxcox(df['Dense4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic = 7.499, p = 0.000505\n"
     ]
    }
   ],
   "source": [
    "F, p = stats.f_oneway(df['Dense1'], df['Dense2'], df['Dense3'], df['Dense4'])\n",
    "# Seeing if the overall model is significant\n",
    "print('F-Statistic = %.3f, p = %f' % (F, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Count   R-squared:                       0.385\n",
      "Model:                            OLS   Adj. R-squared:                  0.333\n",
      "Method:                 Least Squares   F-statistic:                     7.499\n",
      "Date:                Mon, 08 Feb 2021   Prob (F-statistic):           0.000505\n",
      "Time:                        13:37:37   Log-Likelihood:                -130.84\n",
      "No. Observations:                  40   AIC:                             269.7\n",
      "Df Residuals:                      36   BIC:                             276.4\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "Intercept                   13.9018      2.124      6.544      0.000       9.593      18.210\n",
      "C(density_grp)[T.Dense2]    -8.5673      3.004     -2.851      0.007     -14.661      -2.474\n",
      "C(density_grp)[T.Dense3]    -4.9089      3.004     -1.634      0.111     -11.002       1.185\n",
      "C(density_grp)[T.Dense4]     4.7877      3.004      1.594      0.120      -1.306      10.881\n",
      "==============================================================================\n",
      "Omnibus:                        1.940   Durbin-Watson:                   1.826\n",
      "Prob(Omnibus):                  0.379   Jarque-Bera (JB):                0.964\n",
      "Skew:                          -0.207   Prob(JB):                        0.618\n",
      "Kurtosis:                       3.638   Cond. No.                         4.79\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Anova table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(density_grp)</th>\n",
       "      <td>1015.451640</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.499384</td>\n",
       "      <td>0.000505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>1624.855985</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sum_sq    df         F    PR(>F)\n",
       "C(density_grp)  1015.451640   3.0  7.499384  0.000505\n",
       "Residual        1624.855985  36.0       NaN       NaN"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearrange DataFrame\n",
    "newDf = df.stack().to_frame().reset_index().rename(columns={'level_1':'density_grp', 0:'Count'})\n",
    "del newDf['level_0']\n",
    "model = ols('Count ~ C(density_grp)', newDf).fit()\n",
    "print(\"Model summary\")\n",
    "print(model.summary())\n",
    "# Create ANOVA table\n",
    "print(\"Anova table\")\n",
    "res = sm.stats.anova_lm(model, typ= 2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject Null Hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Critical significance level\n",
    "alpha = 0.01\n",
    "if p < alpha:\n",
    "    print(\"Reject Null Hypothesis\")\n",
    "else:\n",
    "    print(\"Failed to reject Null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null hypothesis**: There is no effect of location density on covid cases\n",
    "  \n",
    "  H0: μx = μy\n",
    "  \n",
    "**Alternative hypothesis**: Population location density affects count of covid cases\n",
    "  \n",
    "  H1: μx != μy\n",
    "\n",
    "So the F-statistic and p-values indicate that there is an overall significant effect of density_groups on positive corona cases. \n",
    "Here we choose alpha = 0.01 critical significance value as the outcome of the results of this test would affect the entire populations' life and way of living\n",
    "\n",
    "**Hence H0 rejected**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
